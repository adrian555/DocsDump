# AI Pipelines on container platform

Simplifying lifecycle management for machine learning (ML) and deep learning (DL) is critical for the success of AI applications. From data ingestion and preprocessing, to model training and evaluation, to model deploying and serving, each stage in the ML/DL workflow relies on significant effort from the AI platform managed and monitored by data engineers. Kubernetes automates deployment, scaling, and management of containerized applications. Building AI workflow as pipelines and deploying pipelines on Kubernetes provide the same benefit and further improve the reproducibility and collaboration in AI workflow.

In this talk, we are going to showcase a couple of pipelines examples using Kubeflow Pipelines. IBM Watson Machine Learning service will be used for data processing, model training and serving. Once the audience has the first impression of how AI Pipelines can help, we will continue to compare some open source projects that provide pipelines capability, including Argo, airflow, mlflow, Pachyderm etc. We will end the talk by laying out our criteria for a good AI Pipelines platform and sharing the project we are working on.